{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f4271d1-2281-4958-b30b-154006b13ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Creating gs://injae-sandbox-340804-flux-us-central1/...\n",
      "\u001b[1;31mERROR:\u001b[0m (gcloud.storage.buckets.create) HTTPError 409: Your previous request to create the named bucket succeeded and you already own it.\n",
      "mkdir: cannot create directory ‘content’: File exists\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import socket\n",
    "import re\n",
    "\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "SVC_ACC = !(gcloud config get-value core/account)\n",
    "SVC_ACC = SVC_ACC[0]\n",
    "SERVICE_ACCOUNT = SVC_ACC\n",
    "\n",
    "\n",
    "PROJECT_NUMBER=str(re.search(r'\\d+', SVC_ACC).group())\n",
    "\n",
    "LOCATION=\"us-central1\"\n",
    "\n",
    "UNIQUE_PREFIX = socket.gethostname()\n",
    "UNIQUE_PREFIX = re.sub('[^A-Za-z0-9]+', '', UNIQUE_PREFIX)\n",
    "\n",
    "UID = UNIQUE_PREFIX\n",
    "\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-{UNIQUE_PREFIX}-{LOCATION}\"\n",
    "\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
    "\n",
    "! gcloud config set project $PROJECT_ID\n",
    "! gcloud storage buckets create {BUCKET_URI} --project={PROJECT_ID} --location={LOCATION}\n",
    "\n",
    "!mkdir content\n",
    "!rm -r content/clips/\n",
    "!mkdir content/clips/\n",
    "!rm -r content/frames/\n",
    "!mkdir content/frames/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f26bdcd4-189e-4d68-bc6b-e60318c45b99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "513419e8-ed6c-4d18-989c-935844be17e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The pre-built serving docker image. It contains serving scripts and models.\n",
    "\n",
    "SERVE_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-diffusers-serve-opt:20240605_1400_RC00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b5c645a-174f-4bc7-8b62-bdca0b848778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import glob\n",
    "import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "from io import BytesIO\n",
    "\n",
    "import imageio\n",
    "from diffusers.utils import load_image\n",
    "from google.cloud import aiplatform, storage\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "def load_and_resize_image(image_url):\n",
    "    image = load_image(image_url)\n",
    "    # required by the model\n",
    "    new_width = round(image.size[0] / 8) * 8\n",
    "    new_height = round(image.size[1] / 8) * 8\n",
    "    return image.resize((new_width, new_height))\n",
    "\n",
    "\n",
    "def create_job_name(prefix):\n",
    "    user = os.environ.get(\"USER\")\n",
    "    now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    job_name = f\"{prefix}-{user}-{now}\"\n",
    "    return job_name\n",
    "\n",
    "\n",
    "def image_to_base64(image, format=\"JPEG\"):\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=format)\n",
    "    image_str = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    return image_str\n",
    "\n",
    "\n",
    "def display_video_frames(frames, fps=7, width=500):\n",
    "    io_obj = io.BytesIO()\n",
    "    imageio.mimsave(io_obj, frames, format=\"mp4\")\n",
    "    video_data = base64.b64encode(io_obj.getvalue()).decode(\"utf-8\")\n",
    "    html = \"\"\n",
    "    html += f\"<video controls width={width}>\"\n",
    "    html += f'<source src=\"data:video/mp4;base64,{video_data}\" type=\"video/mp4\">'\n",
    "    html += \"</video>\"\n",
    "    display(HTML(html))\n",
    "\n",
    "\n",
    "def upload_model(model_id, task):\n",
    "    model_name = model_id\n",
    "    serving_env = {\n",
    "        \"MODEL_ID\": model_id,\n",
    "        \"TASK\": task,\n",
    "        \"DEPLOY_SOURCE\": \"notebook\",\n",
    "    }\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=model_name,\n",
    "        serving_container_image_uri=SERVE_DOCKER_URI,\n",
    "        serving_container_ports=[7080],\n",
    "        serving_container_predict_route=\"/predictions/diffusers_serving\",\n",
    "        serving_container_health_route=\"/ping\",\n",
    "        serving_container_environment_variables=serving_env,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_bucket_and_blob_name(filepath):\n",
    "    # The gcs path is of the form gs://<bucket-name>/<blob-name>\n",
    "    gs_suffix = filepath.split(\"gs://\", 1)[1]\n",
    "    return tuple(gs_suffix.split(\"/\", 1))\n",
    "\n",
    "\n",
    "def upload_local_dir_to_gcs(local_dir_path, gcs_dir_path):\n",
    "    \"\"\"Uploads files in a local directory to a GCS directory.\"\"\"\n",
    "    client = storage.Client()\n",
    "    bucket_name = gcs_dir_path.split(\"/\")[2]\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    for local_file in glob.glob(local_dir_path + \"/**\"):\n",
    "        if not os.path.isfile(local_file):\n",
    "            continue\n",
    "        filename = local_file[1 + len(local_dir_path) :]\n",
    "        gcs_file_path = os.path.join(gcs_dir_path, filename)\n",
    "        _, blob_name = get_bucket_and_blob_name(gcs_file_path)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        blob.upload_from_filename(local_file)\n",
    "        print(\"Copied {} to {}.\".format(local_file, gcs_file_path))\n",
    "\n",
    "\n",
    "def download_gcs_blob_as_json(gcs_file_path):\n",
    "    \"\"\"Download GCS blob and convert it to json.\"\"\"\n",
    "    client = storage.Client()\n",
    "    bucket_name, blob_name = get_bucket_and_blob_name(gcs_file_path)\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    return json.loads(blob.download_as_bytes())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4692011f-2072-482c-adbc-3ead801de9b9",
   "metadata": {},
   "source": [
    "## Image to Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72c3a573-2436-45b5-83a8-e329c655df35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Define model and task\n",
    "model_id = \"stabilityai/stable-video-diffusion-img2vid-xt\"\n",
    "task = \"image-to-video\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87fe8d51-2019-49f8-9a18-e44e43b7c756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "image = load_and_resize_image(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/svd/rocket.png\"\n",
    ")\n",
    "\n",
    "# Create a list of frames by repeating the same image\n",
    "frames = [image] * 5  # Repeat the image 5 times\n",
    "\n",
    "# Save the frames as an MP4 video\n",
    "imageio.mimsave(\"rocket_video.mp4\", frames, format=\"mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d090855e-d415-437e-9131-a32c99ebbf78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006683826446533203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading pipeline components...",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4310f6f7b0c455d8501ae8adfc4f10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005299806594848633,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 25,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e39358d8384685923c89abb66e50b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Run inferences locally\n",
    "import torch\n",
    "from diffusers import StableVideoDiffusionPipeline\n",
    "\n",
    "pipe = StableVideoDiffusionPipeline.from_pretrained(\n",
    "    model_id, torch_dtype=torch.float16, variant=\"fp16\"\n",
    ")\n",
    "pipe.enable_model_cpu_offload()\n",
    "\n",
    "# Load the conditioning image\n",
    "image = load_and_resize_image(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/svd/rocket.png\"\n",
    ")\n",
    "\n",
    "generator = torch.manual_seed(42)\n",
    "frames_list = pipe([image], decode_chunk_size=8, generator=generator).frames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50f4cd4-ebd0-4114-bc4e-f4a5828107b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# frames_list\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Assuming frames_list is a list containing a single list of PIL Images\n",
    "frames = frames_list[0] \n",
    "\n",
    "# for frame in frames:\n",
    "#   display(frame)\n",
    "\n",
    "from PIL import Image\n",
    "def image_grid2(imgs, max_cols=5):\n",
    "    num_imgs = len(imgs)\n",
    "    cols = min(num_imgs, max_cols)\n",
    "    rows = (num_imgs - 1) // cols + 1  # Calculate rows based on images and cols\n",
    "    \n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f38e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2 = image_grid2(frames_list[0])\n",
    "grid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34b95c3-4530-4732-ab84-b69f6a21203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.utils import load_image, export_to_gif\n",
    "export_to_gif(frames, \"./main.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314e3211-be18-49db-81b1-e9f0dd0373ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(url='./main.gif') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e9db02",
   "metadata": {},
   "source": [
    "## Final one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82b7a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the conditioning image\n",
    "image = load_and_resize_image('./tulip.jpeg'\n",
    ")\n",
    "\n",
    "generator = torch.manual_seed(42)\n",
    "frames_list = pipe([image], decode_chunk_size=8, generator=generator).frames\n",
    "\n",
    "# frames_list\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Assuming frames_list is a list containing a single list of PIL Images\n",
    "frames = frames_list[0] \n",
    "\n",
    "# for frame in frames:\n",
    "#   display(frame)\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "grid2 = image_grid2(frames)\n",
    "grid2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d311d84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from diffusers.utils import load_image, export_to_gif\n",
    "export_to_gif(frames[10:], \"./tulip_main.gif\")\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(url='./tulip_main.gif') "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
